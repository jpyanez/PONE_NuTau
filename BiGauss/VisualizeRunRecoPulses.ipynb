{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecube import icetray, dataio, dataclasses, simclasses, clsim\n",
    "from icecube.icetray import I3Units, OMKey, I3Frame\n",
    "from icecube.dataclasses import ModuleKey\n",
    "from os.path import expandvars\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import argparse\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats.distributions import chi2\n",
    "import scipy\n",
    "from RecoPulseLikelihoodRatio import likelihoodfit\n",
    "from likelihoodHelpers import log_likelihood_biGauss, log_likelihood_doublePeak, likelihood_ratio_doublePeak, likelihood_ratio_biGauss, biGauss, double_peak\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_file = open('/data/p-one/akatil/analysis/RecoPulses/RecoPulseFitInfo_correcectedchi2.csv', 'r')\n",
    "\n",
    "file_num, frame_num, lepton, DOM, string = ([]), ([]), ([]), ([]), ([])\n",
    "binEntries_mean, success_biGauss, success_doublePeak = ([]), ([]), ([])\n",
    "biGauss_pos, biGauss_wid, biGauss_rat, biGauss_amp = ([]), ([]), ([]), ([])\n",
    "doublePeak_amp1, doublePeak_amp2, doublePeak_pos1, doublePeak_pos2 = ([]), ([]), ([]), ([])\n",
    "doublePeak_rat1, doublePeak_rat2, doublePeak_wid1, doublePeak_wid2 = ([]), ([]), ([]), ([])\n",
    "area_data, area_biGauss_fit, area_doublePeak_fit = ([]), ([]), ([])\n",
    "gof_biGauss, gof_doublePeak = ([]), ([])\n",
    "with read_file:\n",
    "\n",
    "    reader = csv.DictReader(read_file)\n",
    "    \n",
    "    for row in reader:\n",
    "        file_num = np.append(file_num, row['file'])\n",
    "        frame_num = np.append(frame_num, row['frame'])\n",
    "        lepton =np.append(lepton, row['lepton_type'])\n",
    "        DOM = np.append(DOM, row['DOM']) #DOM and string have been interchanged\n",
    "        string = np.append(string, row['string'])\n",
    "        binEntries_mean = np.append(binEntries_mean, float(row['binEntries_mean']))\n",
    "        success_biGauss = np.append(success_biGauss, row['success_biGauss'])\n",
    "        success_doublePeak = np.append(success_doublePeak, row['success_doublePeak'])\n",
    "        biGauss_pos = np.append(biGauss_pos, float(row['biGauss_pos']))\n",
    "        biGauss_wid = np.append(biGauss_wid, float(row['biGauss_wid']))\n",
    "        biGauss_rat = np.append(biGauss_rat, float(row['biGauss_rat']))\n",
    "        biGauss_amp = np.append(biGauss_amp, float(row['biGauss_amp']))\n",
    "        doublePeak_pos1 = np.append(doublePeak_pos1, float(row['doublePeak_pos1']))\n",
    "        doublePeak_wid1 = np.append(doublePeak_wid1, float(row['doublePeak_wid1']))\n",
    "        doublePeak_rat1 = np.append(doublePeak_rat1, float(row['doublePeak_rat1']))\n",
    "        doublePeak_amp1 = np.append(doublePeak_amp1, float(row['doublePeak_amp1']))\n",
    "        doublePeak_pos2 = np.append(doublePeak_pos2, float(row['doublePeak_pos2']))\n",
    "        doublePeak_wid2 = np.append(doublePeak_wid2, float(row['doublePeak_wid2']))\n",
    "        doublePeak_rat2 = np.append(doublePeak_rat2, float(row['doublePeak_rat2']))\n",
    "        doublePeak_amp2 = np.append(doublePeak_amp2, float(row['doublePeak_amp2']))\n",
    "        area_data = np.append(area_data, float(row['area_data']))\n",
    "        area_biGauss_fit = np.append(area_biGauss_fit, float(row['area_biGauss_fit']))\n",
    "        area_doublePeak_fit = np.append(area_doublePeak_fit, float(row['area_doublePeak_fit']))\n",
    "        gof_biGauss = np.append(gof_biGauss, float(row['gof_biGauss']))\n",
    "        gof_doublePeak = np.append(gof_doublePeak, float(row['gof_doublePeak']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cvmfs/icecube.opensciencegrid.org/py2-v3.1.1/RHEL_7_x86_64/lib/python2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in greater\n",
      "  \"\"\"\n",
      "/cvmfs/icecube.opensciencegrid.org/py2-v3.1.1/RHEL_7_x86_64/lib/python2.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in less\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Selecting DOMs with goodness of fit < 2, only double peak fit chi2 values are considered\n",
    "'''\n",
    "gof_bool_biGauss = (gof_biGauss > 0)&(gof_biGauss < 2)\n",
    "gof_bool_dp = (gof_doublePeak > 0)&(gof_doublePeak < 2)\n",
    "\n",
    "select_gof_biGauss = gof_biGauss[gof_bool_dp]\n",
    "select_gof_dp = gof_doublePeak[gof_bool_dp]\n",
    "select_file_num = file_num[gof_bool_dp]\n",
    "select_frame_num = frame_num[gof_bool_dp]\n",
    "select_string = DOM[gof_bool_dp]\n",
    "select_DOM = string[gof_bool_dp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12.9562574 ,  1.94526641,  9.48373854, ..., 14.77778603,\n",
       "       10.41280474,  8.01624411])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gof_biGauss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1392\n",
      "OMKey(9,19,0)\n",
      "Now Histogramming\n",
      "1420\n",
      "OMKey(2,4,0)\n",
      "Now Histogramming\n",
      "1461\n",
      "OMKey(4,4,0)\n",
      "Now Histogramming\n",
      "1465\n",
      "OMKey(4,5,0)\n",
      "Now Histogramming\n",
      "1470\n",
      "OMKey(8,18,0)\n",
      "Now Histogramming\n",
      "1548\n",
      "OMKey(5,1,0)\n",
      "Now Histogramming\n",
      "1587\n",
      "OMKey(3,10,0)\n",
      "Now Histogramming\n",
      "1626\n",
      "OMKey(7,17,0)\n",
      "Now Histogramming\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "plotting the histograms\n",
    "'''\n",
    "\n",
    "for i in range(50, 70):\n",
    "#for i in select_file_num[10:40]:\n",
    "    print(select_file_num[i])\n",
    "    file_name = dataio.I3File('/data/p-one/akatil/step_5_medium_water/NuTau_NuE_20Events/step_5_'+str(select_file_num[i])+'_medium_water_custom_mDOM_recoPulse.i3.gz')\n",
    "    #print('/data/p-one/akatil/step_5_medium_water/NuTau_NuE_20Events/step_5_'+str(select_file_num[i])+'_medium_water_custom_mDOM_recoPulse.i3.gz')\n",
    "    frameList = []\n",
    "    j = 0\n",
    "    while(file_name.more()):\n",
    "        frameList.append(file_name.pop_daq())\n",
    "    frame_number = int(select_frame_num[i])\n",
    "    frame_i = frameList[frame_number]\n",
    "    mctree = frame_i[\"I3MCTree\"]\n",
    "    primary = mctree.primaries\n",
    "    lepton = dataclasses.I3MCTree.first_child(mctree, primary[0].id)    \n",
    "    \n",
    "    omkey = OMKey(int(select_string[i]), int(select_DOM[i]), 0)\n",
    "    print(omkey)\n",
    "    recoPulseMap = frame_i['I3RecoPulses']\n",
    "    recoPulseList = recoPulseMap[omkey]\n",
    "    recoPulse_timeList = np.array([recoPulse.time for recoPulse in recoPulseList])\n",
    "    recoPulse_chargeList = np.array([recoPulse.charge for recoPulse in recoPulseList])\n",
    "    \n",
    "    '''\n",
    "    Removing DOMs with hits less than 100 Hits\n",
    "    '''\n",
    "    if sum(recoPulse_chargeList) < 100:\n",
    "        print(sum(recoPulse_chargeList))\n",
    "        print('exit1')\n",
    "        continue\n",
    "\n",
    "    '''\n",
    "    Calculating the mean and removing the tails\n",
    "    '''\n",
    "\n",
    "    #mean = recoPulse_timeList.mean()\n",
    "    mean = sum(recoPulse_timeList*recoPulse_chargeList)/sum(recoPulse_chargeList) #mean is weighted\n",
    "    select_time = recoPulse_timeList[(recoPulse_timeList > mean-50) & (recoPulse_timeList < mean+50)]\n",
    "    select_charge = recoPulse_chargeList[(recoPulse_timeList > mean-50) & (recoPulse_timeList < mean+50)]\n",
    "    #print('SELECT CHARGE', select_charge, select_time, mean, recoPulse_timeList, recoPulse_chargeList)\n",
    "\n",
    "    if len(select_time) < 10:\n",
    "        print('exit2')\n",
    "        continue\n",
    "\n",
    "    mean_select_time = sum(select_time*select_charge)/sum(select_charge)\n",
    "    max_hitTimes = recoPulse_timeList[(recoPulse_timeList > (mean_select_time-100))&(recoPulse_timeList < (mean_select_time+100))]\n",
    "    max_charge = recoPulse_chargeList[(recoPulse_timeList > (mean_select_time-100))&(recoPulse_timeList < (mean_select_time+100))]\n",
    "\n",
    "    #[using zscore to remove the effect of outliers from the analysis]\n",
    "    z = stats.zscore(max_hitTimes)\n",
    "    max_hitTimes = max_hitTimes[(z>-1.6)&(z < 1.2)]\n",
    "    max_charge = max_charge[(z>-1.6)&(z < 1.2)]\n",
    "\n",
    "    if len(max_hitTimes) < 10:\n",
    "        print('exit3')\n",
    "        continue\n",
    "\n",
    "    #Shifting mean to zero\n",
    "    max_hitTimes_mean = sum(max_hitTimes*max_charge)/sum(max_charge)\n",
    "    timestamps = max_hitTimes - max_hitTimes_mean\n",
    "    final_mean = timestamps.mean()\n",
    "\n",
    "    '''\n",
    "    Histogramming the data from simulation\n",
    "    '''\n",
    "    print('Now Histogramming')\n",
    "    bins = np.arange(min(timestamps), max(timestamps), 1)\n",
    "    num, bin_edges = np.histogram(timestamps, bins=bins, weights=max_charge)\n",
    "    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "                    \n",
    "    #removing bins with < 0 entries ---> Recommended for binned likelihood\n",
    "    entries_in_bins = num[num > 0]\n",
    "    bin_centers = bin_centers[num > 0]\n",
    "\n",
    "    #Degrees of freedom should be greater than zero!\n",
    "    if len(entries_in_bins) < 8:\n",
    "        continue\n",
    "\n",
    "    #Getting data for the chi2 fit\n",
    "    chi2_entries_in_bins = entries_in_bins[entries_in_bins > 10]\n",
    "    chi2_bin_centers = bin_centers[entries_in_bins > 10]\n",
    "\n",
    "    num_dataPoints = len(entries_in_bins)\n",
    "    area_data = sum(entries_in_bins)\n",
    "    mean_entries = entries_in_bins.mean()\n",
    "\n",
    "    '''\n",
    "    Fitting bifurcated Gaussian and double bifurcated gaussian to\n",
    "    the mcpe hit time distributions for both tau and electron.\n",
    "    '''\n",
    "\n",
    "    #Single Peak\n",
    "\n",
    "    nll = lambda *args: log_likelihood_biGauss(*args)\n",
    "    initial_biGauss = np.array([final_mean, 50, 5, max(entries_in_bins)])\n",
    "    bnds_biGauss = ((min(bin_centers), max(bin_centers)), (0, 500), (0, 10), (0, 1e6))\n",
    "    soln_biGauss = minimize(log_likelihood_biGauss, initial_biGauss,\n",
    "                                    args=(entries_in_bins, bin_centers),\n",
    "                                    method='Powell',\n",
    "                                    bounds = bnds_biGauss)\n",
    "\n",
    "    #Double Peak\n",
    "\n",
    "    nll = lambda *args: log_likelihood_doublePeak(*args)\n",
    "    initial_doublePeak = np.array([min(bin_centers)+10, 20, 1, max(entries_in_bins), final_mean, 20, 1, max(entries_in_bins)])\n",
    "    bnds_doublePeak = ((min(bin_centers), final_mean), (0, 500), (0, 10), (0, 1e6),\n",
    "                        (final_mean, max(bin_centers)), (0, 500), (0, 10), (0,1e6))\n",
    "    soln_doublePeak = minimize(log_likelihood_doublePeak, initial_doublePeak,\n",
    "                                args=(entries_in_bins, bin_centers),\n",
    "                                method='Powell',\n",
    "                                bounds=bnds_doublePeak)\n",
    "    \n",
    "    LR_biGauss = likelihood_ratio_biGauss(bin_centers, entries_in_bins, soln_biGauss.x[0],\n",
    "                                              soln_biGauss.x[1], soln_biGauss.x[2], soln_biGauss.x[3])\n",
    "    LR_doublePeak = likelihood_ratio_doublePeak(bin_centers, entries_in_bins, soln_doublePeak.x[0],\n",
    "                                                    soln_doublePeak.x[1],soln_doublePeak.x[2],\n",
    "                                                    soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                                    soln_doublePeak.x[5], soln_doublePeak.x[6],\n",
    "                                                    soln_doublePeak.x[7])\n",
    "    \n",
    "    '''\n",
    "    goodness of fit - Chi2 = 2*ln(LR)\n",
    "    '''\n",
    "    gof_DOM_biGauss = (2*LR_biGauss)/(num_dataPoints - 4)\n",
    "    gof_DOM_doublePeak = (2*LR_doublePeak)/(num_dataPoints - 8)\n",
    "    \n",
    "    if gof_DOM_doublePeak != gof_DOM_doublePeak:\n",
    "        print('PARAMETERS -', soln_doublePeak.x[0], soln_doublePeak.x[1],soln_doublePeak.x[2],\n",
    "                                                    soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                                    soln_doublePeak.x[5], soln_doublePeak.x[6],\n",
    "                                                    soln_doublePeak.x[7])\n",
    "        \n",
    "        def log_likelihood_doublePeak_test(theta, n, x):\n",
    "            pos1, wid1, r1, amp1, pos2, wid2, r2, amp2 = theta\n",
    "            model = double_peak(x, pos1, wid1, r1, amp1, pos2, wid2, r2, amp2)\n",
    "            L = model - (n*np.log(model))\n",
    "            print('*****************Double Peak***************', int(i), omkey)\n",
    "            print(theta, np.sum(L))\n",
    "            return np.sum(L)\n",
    "        \n",
    "        \n",
    "        soln_doublePeak_test = minimize(log_likelihood_doublePeak_test, initial_doublePeak,\n",
    "                            args=(entries_in_bins, bin_centers),\n",
    "                            method='Powell',\n",
    "                            bounds=bnds_doublePeak)\n",
    "    \n",
    "        '''\n",
    "        (x, y) values for the fit\n",
    "        '''\n",
    "        #x = bin_centers\n",
    "        x = np.linspace(min(bin_centers), max(bin_centers), 1000)\n",
    "        y_biGauss = biGauss(x, soln_biGauss.x[0],\n",
    "                            soln_biGauss.x[1], soln_biGauss.x[2], soln_biGauss.x[3])\n",
    "        y_doublePeak = double_peak(x, soln_doublePeak.x[0], soln_doublePeak.x[1],\n",
    "                                        soln_doublePeak.x[2], soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                        soln_doublePeak.x[5], soln_doublePeak.x[6], soln_doublePeak.x[7])\n",
    "    \n",
    "    \n",
    "                    \n",
    "        plt.figure(figsize=(10,9))\n",
    "        _ = plt.hist(timestamps, bins=bins, weights=max_charge, histtype='step')\n",
    "        #plt.plot(x, y_biGauss, '-', c = 'k')\n",
    "        plt.plot(x, y_doublePeak, '-', c = 'r')\n",
    "        plt.title(str(lepton.type) +' Double Peak(Chi2/dof)- '+ str(select_gof_dp[i])+' LR - '+str(gof_DOM_doublePeak))\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame_in_file = select_frame_num[select_file_num == i]\n",
    "    frame_number = 0\n",
    "    for frame in file:\n",
    "        for j in frame_in_file:\n",
    "            if frame_number == int(j):\n",
    "                mctree = frame[\"I3MCTree\"]\n",
    "                primary = mctree.primaries\n",
    "                lepton = dataclasses.I3MCTree.first_child(mctree, primary[0].id)\n",
    "                \n",
    "                recoPulseMap = frame['I3RecoPulses']\n",
    "                select_string_in_frame = select_string[(select_file_num == i) & (select_frame_num == j)]\n",
    "                \n",
    "                for k in select_string_in_frame:\n",
    "                    select_DOM_with_string = select_DOM[(select_file_num == i) & (select_frame_num == j) & (select_string == k)]\n",
    "                    omkey = OMKey(int(k), int(select_DOM_with_string[0]), 0)\n",
    "                    print('OMKEY', omkey)\n",
    "                    print(num)\n",
    "                    print(i, j, k, int(select_DOM_with_string[0]))\n",
    "                    print(i, select_frame_num[num], select_string[num], select_DOM[num])\n",
    "                    select_gof_DOM_biGauss = select_gof_biGauss[(select_file_num == i) & (select_frame_num == j) & (select_string == k)& (select_DOM == select_DOM_with_string[0])]\n",
    "                    select_gof_DOM_dp = select_gof_dp[(select_file_num == i) & (select_frame_num == j) & (select_string == k)& (select_DOM == select_DOM_with_string[0])]\n",
    "                    \n",
    "                    recoPulseList = recoPulseMap[omkey]\n",
    "                    recoPulse_timeList = np.array([recoPulse.time for recoPulse in recoPulseList])\n",
    "                    recoPulse_chargeList = np.array([recoPulse.charge for recoPulse in recoPulseList])\n",
    "                    \n",
    "                    '''\n",
    "                    Removing DOMs with hits less than 100 Hits\n",
    "                    '''\n",
    "                    if sum(recoPulse_chargeList) < 100:\n",
    "                        print('exit1')\n",
    "                        continue\n",
    "\n",
    "                    '''\n",
    "                    Calculating the mean and removing the tails\n",
    "                    '''\n",
    "\n",
    "                    #mean = recoPulse_timeList.mean()\n",
    "                    mean = sum(recoPulse_timeList*recoPulse_chargeList)/sum(recoPulse_chargeList) #mean is weighted\n",
    "                    select_time = recoPulse_timeList[(recoPulse_timeList > mean-50) & (recoPulse_timeList < mean+50)]\n",
    "                    select_charge = recoPulse_chargeList[(recoPulse_timeList > mean-50) & (recoPulse_timeList < mean+50)]\n",
    "                    #print('SELECT CHARGE', select_charge, select_time, mean, recoPulse_timeList, recoPulse_chargeList)\n",
    "\n",
    "                    if len(select_time) < 10:\n",
    "                        print('exit2')\n",
    "                        continue\n",
    "\n",
    "                    mean_select_time = sum(select_time*select_charge)/sum(select_charge)\n",
    "                    max_hitTimes = recoPulse_timeList[(recoPulse_timeList > (mean_select_time-100))&(recoPulse_timeList < (mean_select_time+100))]\n",
    "                    max_charge = recoPulse_chargeList[(recoPulse_timeList > (mean_select_time-100))&(recoPulse_timeList < (mean_select_time+100))]\n",
    "\n",
    "                    #[using zscore to remove the effect of outliers from the analysis]\n",
    "                    z = stats.zscore(max_hitTimes)\n",
    "                    max_hitTimes = max_hitTimes[(z>-1.6)&(z < 1.2)]\n",
    "                    max_charge = max_charge[(z>-1.6)&(z < 1.2)]\n",
    "\n",
    "                    if len(max_hitTimes) < 10:\n",
    "                        print('exit3')\n",
    "                        continue\n",
    "\n",
    "                    #Shifting mean to zero\n",
    "                    max_hitTimes_mean = sum(max_hitTimes*max_charge)/sum(max_charge)\n",
    "                    timestamps = max_hitTimes - max_hitTimes_mean\n",
    "                    final_mean = timestamps.mean()\n",
    "\n",
    "                    '''\n",
    "                    Histogramming the data from simulation\n",
    "                    '''\n",
    "                    print('Now Histogramming')\n",
    "                    bins = np.arange(min(timestamps), max(timestamps), 1)\n",
    "                    num, bin_edges = np.histogram(timestamps, bins=bins, weights=max_charge)\n",
    "                    bin_centers = (bin_edges[:-1]+bin_edges[1:])/2\n",
    "                    \n",
    "                    #removing bins with < 0 entries ---> Recommended for binned likelihood\n",
    "                    entries_in_bins = num[num > 0]\n",
    "                    bin_centers = bin_centers[num > 0]\n",
    "\n",
    "                    #Degrees of freedom should be greater than zero!\n",
    "                    if len(entries_in_bins) < 8:\n",
    "                        continue\n",
    "\n",
    "                    #Getting data for the chi2 fit\n",
    "                    chi2_entries_in_bins = entries_in_bins[entries_in_bins > 10]\n",
    "                    chi2_bin_centers = bin_centers[entries_in_bins > 10]\n",
    "\n",
    "                    num_dataPoints = len(entries_in_bins)\n",
    "                    area_data = sum(entries_in_bins)\n",
    "                    mean_entries = entries_in_bins.mean()\n",
    "\n",
    "                    '''\n",
    "                    Fitting bifurcated Gaussian and double bifurcated gaussian to\n",
    "                    the mcpe hit time distributions for both tau and electron.\n",
    "                    '''\n",
    "\n",
    "                    #Single Peak\n",
    "\n",
    "                    nll = lambda *args: log_likelihood_biGauss(*args)\n",
    "                    initial_biGauss = np.array([final_mean, 50, 5, max(entries_in_bins)])\n",
    "                    bnds_biGauss = ((min(bin_centers), max(bin_centers)), (0, 500), (0, 10), (0, 1e6))\n",
    "                    soln_biGauss = minimize(log_likelihood_biGauss, initial_biGauss,\n",
    "                                            args=(entries_in_bins, bin_centers),\n",
    "                                            method='Powell',\n",
    "                                            bounds = bnds_biGauss)\n",
    "\n",
    "                    #Double Peak\n",
    "\n",
    "                    nll = lambda *args: log_likelihood_doublePeak(*args)\n",
    "                    initial_doublePeak = np.array([min(bin_centers)+10, 20, 1, max(entries_in_bins), final_mean, 20, 1, max(entries_in_bins)])\n",
    "                    bnds_doublePeak = ((min(bin_centers), final_mean), (0, 500), (0, 10), (0, 1e6),\n",
    "                                        (final_mean, max(bin_centers)), (0, 500), (0, 10), (0,1e6))\n",
    "                    soln_doublePeak = minimize(log_likelihood_doublePeak, initial_doublePeak,\n",
    "                                                args=(entries_in_bins, bin_centers),\n",
    "                                                method='Powell',\n",
    "                                                bounds=bnds_doublePeak)\n",
    "                    \n",
    "                    '''\n",
    "                    (x, y) values for the fit\n",
    "                    '''\n",
    "                    #x = bin_centers\n",
    "                    x = np.linspace(min(bin_centers), max(bin_centers), 1000)\n",
    "                    y_biGauss = biGauss(x, soln_biGauss.x[0],\n",
    "                                            soln_biGauss.x[1], soln_biGauss.x[2], soln_biGauss.x[3])\n",
    "                    y_doublePeak = double_peak(x, soln_doublePeak.x[0], soln_doublePeak.x[1],\n",
    "                                                        soln_doublePeak.x[2], soln_doublePeak.x[3], soln_doublePeak.x[4],\n",
    "                                                        soln_doublePeak.x[5], soln_doublePeak.x[6], soln_doublePeak.x[7])\n",
    "                    \n",
    "                    plt.figure(figsize=(10,9))\n",
    "                    _ = plt.hist(timestamps, bins=bins, weights=max_charge, histtype='step')\n",
    "                    plt.plot(x, y_biGauss, '-', c = 'k')\n",
    "                    plt.plot(x, y_doublePeak, '-', c = 'r')\n",
    "                    plt.title(str(lepton.type)+' '+ str(select_gof_DOM_biGauss) +' '+ str(select_gof_DOM_dp))\n",
    "                \n",
    "            frame_number += 1    \n",
    "    num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
